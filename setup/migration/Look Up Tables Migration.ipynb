{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo pip install ibm_db\n",
    "import ibm_db\n",
    "# conda install -c conda-forge ibm_db\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "# conda install -c anaconda psycopg2\n",
    "import sqlalchemy\n",
    "# conda install -c anaconda sqlalchemy\n",
    "import matplotlib as plt\n",
    "import requests\n",
    "# conda install -c anaconda requests\n",
    "from requests.auth import HTTPDigestAuth\n",
    "import json\n",
    "# conda install -c jmcmurray json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "# conda install -c anaconda zlib\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import ibm_db_sa\n",
    "# conda install -c auto ibm_db_sa\n",
    "# pip install ibm-db-sa\n",
    "\n",
    "import ibm_db_dbi\n",
    "\n",
    "import logging\n",
    "\n",
    "import datetime\n",
    "\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logs.log',level=logging.DEBUG)\n",
    "\n",
    "\n",
    "POSTGRES_ADDRESS = 'localhost'\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_USERNAME = 'ebreshna_user'\n",
    "POSTGRES_PASSWORD = 'secret'\n",
    "POSTGRES_DBNAME = 'ebreshna'\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME, password=POSTGRES_PASSWORD, ipaddress=POSTGRES_ADDRESS, port=POSTGRES_PORT, dbname=POSTGRES_DBNAME))\n",
    "# conn = psycopg2.connect(\"host=localhost dbname=asims_test user=asims_user password=secret port=5432\")\n",
    "# cur = conn.cursor()\n",
    "psql_engine = create_engine(postgres_str)\n",
    "\n",
    "# SQL SERVER CONNECTION\n",
    "DB2_ADDRESS = 'localhost'\n",
    "DB2_PORT = '51000'\n",
    "DB2_USERNAME = 'mpower_user'\n",
    "DB2_PASSWORD = 'secret'\n",
    "DB2_DBNAME = 'mpower'\n",
    "# db2_engine = create_engine('ibm_db_sa+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "# db2_engine = create_engine(\"db2+ibm_db://user:pass@10.10.100.47:51000/mpower\")\n",
    "# conn = ibm_db.connect(\"DATABASE=mpower;HOSTNAME=host;PORT=50000;PROTOCOL=TCPIP;UID=username;PWD=password;\", \"\", \"\")\n",
    "db2_conn = ibm_db.connect(\"DRIVER={{IBM DB2 ODBC DRIVER}};DATABASE=mpower;HOSTNAME=10.10.100.47;PORT=51000;PROTOCOL=TCPIP;UID=db2inst1;PWD=db2inst1;\", \"\", \"\")\n",
    "# this is required to enable database access through Pandas\n",
    "db2_conni =  ibm_db_dbi.connect(u\"DRIVER={{IBM DB2 ODBC DRIVER}};DATABASE=mpower;HOSTNAME=10.10.100.47;PORT=51000;PROTOCOL=TCPIP;UID=db2inst1;PWD=db2inst1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Look Up Tables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Migrated Records (ANOMALIES_LIST): Total Src Records: 61834 Total migrated Records to dest: 123668\n"
     ]
    }
   ],
   "source": [
    "# Region\n",
    "cols_map = [\n",
    "    {'src_col': 'JUNCTION', 'des_col': 'junction', 'src_dtype': 'String', 'des_dtype': 'String'},\n",
    "    {'src_col': 'ACCOUNT_NO', 'des_col': 'account_no', 'src_dtype': 'String', 'des_dtype': 'String'},\n",
    "    {'src_col': 'CUSTMER_NAME', 'des_col': 'cutomer_name', 'src_dtype': 'String', 'des_dtype': 'String'},\n",
    "    {'src_col': '', 'des_col': 'deleted', 'src_dtype': 'String', 'des_dtype': 'Boolean', 'des_value': 'false'}\n",
    "]\n",
    "\n",
    "migrated_row_count = migrate_data(db2_conni, psql_engine, 'DABS.ANOMALIES_LIST', 'public', '\"ANOMALIES_LIST\"', cols_map)\n",
    "print(\"Total Migrated Records (ANOMALIES_LIST): \" + str(migrated_row_count))\n",
    "\n",
    "\n",
    "\n",
    "# sql = \"SELECT * FROM DABS.ANOMALIES_LIST;\"\n",
    "# df = pd.read_sql(sql, db2_conni)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ibm_db import connect\n",
    "# Careful with the punctuation here - we have 3 arguments.\n",
    "# The first is a big string with semicolons in it.\n",
    "# (Strings separated by only whitespace, newlines included,\n",
    "#  are automatically joined together, in case you didn't know.)\n",
    "# The last two are emptry strings.\n",
    "#connection = connect('DATABASE=<database name>;'\n",
    "#                     'HOSTNAME=<database ip>;'  # 127.0.0.1 or localhost works if it's local\n",
    "#                     'PORT=<database port>;'\n",
    "#                     'PROTOCOL=TCPIP;'\n",
    "#                     'UID=<database username>;'\n",
    "#                     'PWD=<username password>;', '', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ibm_db never actually give us results. Instead, we need to call one of the fetch methods on the command, repeatedly, to get the results this helper function to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_db2_results(command):\n",
    "    from ibm_db import fetch_assoc\n",
    "\n",
    "    ret = []\n",
    "    result = fetch_assoc(command)\n",
    "    while result:\n",
    "        # This builds a list in memory. Theoretically, if there's a lot of rows,\n",
    "        # we could run out of memory. In practice, I've never had that happen.\n",
    "        # If it's ever a problem, you could use\n",
    "        #     yield result\n",
    "        # Then this function would become a generator. You lose the ability to access\n",
    "        # results by index or slice them or whatever, but you retain\n",
    "        # the ability to iterate on them.\n",
    "        ret.append(result)\n",
    "        result = fetch_assoc(command)\n",
    "    return ret  # Ditch this line if you choose to use a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can easily do something like get the information on all the tables in your database with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'connection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a04dc3ea47c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mibm_db\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'connection' is not defined"
     ]
    }
   ],
   "source": [
    "from ibm_db import tables\n",
    "\n",
    "t = fetch_db2_results(tables(connection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a sql command on DB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ac175aa4e99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mibm_db\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexec_immediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LIST * FROM '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TABLE_NAME'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Using our list of tables t from before...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_immediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "from ibm_db import exec_immediate\n",
    "\n",
    "sql = 'LIST * FROM ' + t[170]['TABLE_NAME']  # Using our list of tables t from before...\n",
    "rows = fetch_db2_results(exec_immediate(connection, sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres username, password, and database name\n",
    "POSTGRES_ADDRESS = 'localhost'\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_USERNAME = 'asims_user'\n",
    "POSTGRES_PASSWORD = 'secret'\n",
    "POSTGRES_DBNAME = 'ebreshna_test'\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME, password=POSTGRES_PASSWORD, ipaddress=POSTGRES_ADDRESS, port=POSTGRES_PORT, dbname=POSTGRES_DBNAME))\n",
    "# Create the connection\n",
    "cnx = create_engine(postgres_str)\n",
    "\n",
    "# ASIMS ENDPOINT\n",
    "ASIMS_API_ENDPOINT = 'http://localhost:8090/odkx/odktables/db_sync/'\n",
    "\n",
    "# List all table names of ODKX from Sync Endpoint\n",
    "odkx_db_table_names = ['NSIA_HOUSEHOLD_MALE',\n",
    "                    'NSIA_HOUSEHOLD_FEMALE', \n",
    "                    'NSIA_ROSTER_MALE', \n",
    "                    'NSIA_ROSTER_FEMALE', \n",
    "                    'NSIA_LABOUR_MALE', \n",
    "                    'NSIA_CHILD_LABOUR', \n",
    "                    'NSIA_HEALTH', \n",
    "                    'SHURA', \n",
    "                    'MARKET_PRICE', \n",
    "                    'WATER_TESTING', \n",
    "                    'NSIA_CAPI', \n",
    "                    'NSIA_CAPI_LIST']\n",
    "odkx_db_table_prefix = '__ODKTABLES__TABLE_'\n",
    "odkx_db_schema = 'odk_sync.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
